{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms,datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d3813fc628a4a50b013b48437f09f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/train-images-idx3-ubyte.gz to MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c472d3112d5491ebf1e183ecfcfaabe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/train-labels-idx1-ubyte.gz to MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8a1ebc5916464aaf0174c489f7574f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d335a1697b2e41ba872a3f08a4d753ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train = datasets.MNIST('', train = True, download = True, transform = transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test = datasets.MNIST('', train = False, download = True, transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size = 10, shuffle = True)\n",
    "\n",
    "testset = torch.utils.data.DataLoader(test, batch_size = 10, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([5, 8, 6, 1, 7, 2, 2, 0, 2, 4])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = data[0][0], data[1][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 8, 6, 1, 7, 2, 2, 0, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "print(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# So, basically data[1][0] is just 5, however, let us analyse the associated image with it, that is, data[0][0]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(data[0][0].view(28,28))\n",
    "plt.show()\n",
    "\n",
    "print(data[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very important thing to note that is in this case, input parameters might not be scaled. For example, The images are 8 bit quantized, so, the values range from 0 - 255. In that case, we simply have to divide the number by 255 so as to normalize it between 0 and 1. (or even -1 to 1 for that matter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing to think about is wheter our dataset is balenced? Since, given the required number of occurrences of each of the digit in the MNIST dataset, say, if the number of 5's are far more than each of the other digits, this might become an issue, since the NN might also spit out 5's more frequently due to its higher occurrance. So, we need to make sure that the data is balenced. Let us check that,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n",
      "0: 9.871666666666666%\n",
      "1: 11.236666666666666%\n",
      "2: 9.93%\n",
      "3: 10.218333333333334%\n",
      "4: 9.736666666666666%\n",
      "5: 9.035%\n",
      "6: 9.863333333333333%\n",
      "7: 10.441666666666666%\n",
      "8: 9.751666666666667%\n",
      "9: 9.915000000000001%\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "counter_dict = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0}\n",
    "\n",
    "for data in trainset:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)]+= 1\n",
    "        total+= 1\n",
    "\n",
    "print(counter_dict)\n",
    "\n",
    "for i in counter_dict:\n",
    "    print(f\"{i}: {counter_dict[i]/total*100.0}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, here we see that the data is roughly balenced, so, we can use this data. Now, let us jump to the making of the NN, through which we shall pass the training set through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim = 1)\n",
    "        \n",
    "        \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.3993, -2.1045, -2.2159, -2.3624, -2.3029, -2.4378, -2.3796, -2.2727,\n",
      "         -2.1475, -2.4727]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Now that we have made the neural network, let us test it, by adding a random image into it\n",
    "\n",
    "X = torch.randn((28,28))\n",
    "X = X.view(-1,28*28)\n",
    "output = net(X)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the only thing that is left is to specify the loss function and write the optmizer function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0514, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0228, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0248, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Now let us jump to the training part\n",
    "# Let us set the epoch = 3, that is, we shall go through the whole dataset 3 times\n",
    "\n",
    "for epoch in range(3):\n",
    "    for data in trainset:\n",
    "        X,y = data\n",
    "        net.zero_grad() # we set the gradients to zero before we update the loss function\n",
    "        output = net(X.view(-1,784))\n",
    "        loss = F.nll_loss(output,y)\n",
    "        loss.backward() # Backpropagation for gradient calculation\n",
    "        optimizer.step()\n",
    "    print(loss)\n",
    "# All these computations are currently done in CPU, but can also be done in GPU, for faster calculation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.96\n"
     ]
    }
   ],
   "source": [
    "# Now that the training is done, let us check the accuracy of our model,\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X,y = data\n",
    "        output = net(X.view(-1,784))\n",
    "        for idx,i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct+= 1\n",
    "            total+= 1\n",
    "\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9)\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(X[2].view(28,28))\n",
    "plt.show()\n",
    "print(torch.argmax(net(X[2].view(-1,784))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
